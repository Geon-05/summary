{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 원본 텍스트 =====\n",
      "오늘 날씨가 너무 좋아서 점심 먹고 산책을 할까 고민 중이야. 아침에는 약간 흐렸는데, 오후 들어서 해가 나더라.\n",
      "===== 요약 결과 =====\n",
      "산책을 할까 고민 중이며 아침에는 흐렸다가 오후 들어서 해가 나곤 한다.\n",
      "\n",
      "===== 원본 텍스트 =====\n",
      "데이터 사이언스는 다양한 분야에서 활용된다. 빅데이터 시대에는 방대한 정보를 잘 가공해 인사이트를 뽑아내는 것이 중요하다.\n",
      "===== 요약 결과 =====\n",
      "빅데이터 시대에에는 방대한 정보를 가공해 인사이트를 뽑아내는 데이터 사이언스가 다양한 분야에서 활용된다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "import evaluate\n",
    "\n",
    "# 모델 / 토크나이저 로드 경로 지정\n",
    "MODEL_DIR = \"summary_model_final\"\n",
    "\n",
    "def test_model(input_text, model_dir=MODEL_DIR, max_source_length=1024, max_target_length=128):\n",
    "    \"\"\"\n",
    "    학습 완료된 KoBART 모델로 요약을 수행하는 함수\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1) 토크나이저 / 모델 불러오기\n",
    "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_dir)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 2) 입력 텍스트 토큰화\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_source_length,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    # 3) 요약 생성 (샘플링 or 빔서치)\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            num_beams=4,\n",
    "            max_length=max_target_length,\n",
    "            early_stopping=True\n",
    "            # 또는 샘플링 모드\n",
    "            # do_sample=True, top_k=50, top_p=0.95\n",
    "        )\n",
    "\n",
    "    # 4) 디코딩\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 평가용 메트릭 (ROUGE)\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    # 테스트용 입력(들)을 정의\n",
    "    test_texts = [\n",
    "        \"\"\" \n",
    "        오늘 날씨가 너무 좋아서 점심 먹고 산책을 할까 고민 중이야. 아침에는 약간 흐렸는데, 오후 들어서 해가 나더라.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        데이터 사이언스는 다양한 분야에서 활용된다. 빅데이터 시대에는 방대한 정보를 잘 가공해 인사이트를 뽑아내는 것이 중요하다.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    # 실제 테스트 실행\n",
    "    predictions = []\n",
    "    for text in test_texts:\n",
    "        summary = test_model(text)\n",
    "        predictions.append(summary)\n",
    "        print(\"===== 원본 텍스트 =====\")\n",
    "        print(text.strip())\n",
    "        print(\"===== 요약 결과 =====\")\n",
    "        print(summary)\n",
    "        print(\"\")\n",
    "\n",
    "    # (선택) 참조 요약문이 있다면 ROUGE 평가\n",
    "    # references = [\"해당 문장에 대한 참조 요약1\", \"참조 요약2\"]\n",
    "    # results = rouge.compute(predictions=predictions, references=references)\n",
    "    # print(\"ROUGE Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 원본 텍스트 =====\n",
      "Alice: 안녕, 오늘 날씨가 정말 좋지 않아?\n",
      "        Bob: 그러게, 어제는 비가 오더니 오늘은 맑아서 기분이 좋아!\n",
      "        Alice: 나도! 이렇게 날씨 좋은 날엔 산책이 최고인 것 같아.\n",
      "        Bob: 맞아, 이따 점심 먹고 같이 산책이나 할까?\n",
      "        Alice: 그러자. 어디 갈지 생각해둔 데 있어?\n",
      "        Bob: 그냥 집 근처 공원에 가면 좋을 것 같아. 가는 길에 카페도 있으니까.\n",
      "===== 요약 결과 =====\n",
      "Alice:                .\n",
      "\n",
      "===== 원본 텍스트 =====\n",
      "오늘은 주요 국가들의 경제 상황과 전망에 대해 살펴보겠습니다. \n",
      "        지난 분기에 비해 수출은 소폭 감소했지만, 내수시장이 여전히 활발하게 유지되는 모습입니다. \n",
      "        전문가들은 하반기에도 비슷한 추세가 이어질 것으로 예상하고 있습니다.\n",
      "===== 요약 결과 =====\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import evaluate\n",
    "\n",
    "# 1. 모델 / 토크나이저 로드 경로 지정\n",
    "MODEL_DIR = \"./summary_model_final\"  # 학습이 끝난 모델이 저장된 디렉토리\n",
    "\n",
    "def test_model(input_text, model_dir=MODEL_DIR, max_source_length=1024, max_target_length=128):\n",
    "    \"\"\"\n",
    "    학습 완료된 Pegasus 모델로 요약을 수행하는 함수\n",
    "    \"\"\"\n",
    "    # GPU 사용 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1) 토크나이저 / 모델 불러오기\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_dir)\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_dir)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 2) 입력 텍스트 토큰화\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_source_length,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    # 3) 요약 생성\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            do_sample=True,      # 샘플링 모드\n",
    "            top_k=50, \n",
    "            top_p=0.95,\n",
    "            max_length=256\n",
    "        )\n",
    "\n",
    "    # 4) 디코딩\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 2. 평가용 메트릭 (ROUGE) 로드\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    # 3. 테스트용 입력(들)을 정의\n",
    "    test_texts = [\n",
    "        \"\"\" \n",
    "        Alice: 안녕, 오늘 날씨가 정말 좋지 않아?\n",
    "        Bob: 그러게, 어제는 비가 오더니 오늘은 맑아서 기분이 좋아!\n",
    "        Alice: 나도! 이렇게 날씨 좋은 날엔 산책이 최고인 것 같아.\n",
    "        Bob: 맞아, 이따 점심 먹고 같이 산책이나 할까?\n",
    "        Alice: 그러자. 어디 갈지 생각해둔 데 있어?\n",
    "        Bob: 그냥 집 근처 공원에 가면 좋을 것 같아. 가는 길에 카페도 있으니까.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        오늘은 주요 국가들의 경제 상황과 전망에 대해 살펴보겠습니다. \n",
    "        지난 분기에 비해 수출은 소폭 감소했지만, 내수시장이 여전히 활발하게 유지되는 모습입니다. \n",
    "        전문가들은 하반기에도 비슷한 추세가 이어질 것으로 예상하고 있습니다.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    # 4. 실제 테스트 실행\n",
    "    predictions = []\n",
    "    for text in test_texts:\n",
    "        summary = test_model(text)  # 추론\n",
    "        predictions.append(summary)\n",
    "        print(\"===== 원본 텍스트 =====\")\n",
    "        print(text.strip())\n",
    "        print(\"===== 요약 결과 =====\")\n",
    "        print(summary)\n",
    "        print(\"\")\n",
    "\n",
    "    # 5. (선택) 만약 참조 요약문이 있다면, ROUGE 평가도 가능\n",
    "    #    예: references = [\"참조 요약1\", \"참조 요약2\"]\n",
    "    #    results = rouge.compute(predictions=predictions, references=references)\n",
    "    #    print(\"ROUGE Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

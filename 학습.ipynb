{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 84364\n",
      "Validation 데이터 개수: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3788fff1a3f40bca093d39f532383dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/21091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 203\u001b[0m\n\u001b[0;32m    196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m    197\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    198\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    199\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# 단일 GPU라면 보통 scalar지만, .mean() 유지 가능\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    205\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    BartForConditionalGeneration,\n",
    "    PreTrainedTokenizerFast,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import evaluate\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# 1. 데이터 로드 (단일 JSON 파일에서)\n",
    "# -------------------------\n",
    "with open(\"train_data_all.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"val_data_all.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "train_input_texts = [d[\"passage\"] for d in train_data]\n",
    "train_target_summaries = [d[\"summary\"] for d in train_data]\n",
    "\n",
    "val_input_texts = [d[\"passage\"] for d in val_data]\n",
    "val_target_summaries = [d[\"summary\"] for d in val_data]\n",
    "\n",
    "print(f\"Train 데이터 개수: {len(train_input_texts)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_input_texts)}\")\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 3\n",
    "\n",
    "# -------------------------\n",
    "# 2. 모델 및 토크나이저 로드 (KoBART)\n",
    "# -------------------------\n",
    "model_name = \"gogamza/kobart-base-v1\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, config=model_config)\n",
    "\n",
    "# -------------------------\n",
    "# 3. GPU 사용 설정 (단일 GPU)\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -------------------------\n",
    "# 4. 토큰화 함수\n",
    "# -------------------------\n",
    "def preprocess_for_model(\n",
    "    input_texts, \n",
    "    target_summaries, \n",
    "    tokenizer, \n",
    "    max_input_length=1024, \n",
    "    max_target_length=128\n",
    "):\n",
    "    inputs = tokenizer(\n",
    "        input_texts,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        target_summaries,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return inputs, targets\n",
    "\n",
    "# -------------------------\n",
    "# 5. 실제 토큰화 실행\n",
    "# -------------------------\n",
    "train_inputs, train_targets = preprocess_for_model(train_input_texts, train_target_summaries, tokenizer)\n",
    "val_inputs, val_targets = preprocess_for_model(val_input_texts, val_target_summaries, tokenizer)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Dataset 클래스 정의\n",
    "# -------------------------\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
    "            \"labels\": self.targets[\"input_ids\"][idx],\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# 7. Dataset 및 DataLoader\n",
    "# -------------------------\n",
    "train_dataset = SummaryDataset(train_inputs, train_targets)\n",
    "val_dataset = SummaryDataset(val_inputs, val_targets)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 8. 옵티마이저 및 스케줄러\n",
    "# -------------------------\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 9. 평가용 메트릭 (ROUGE)\n",
    "# -------------------------\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# -------------------------\n",
    "# 10. 검증(Validation) 함수\n",
    "# -------------------------\n",
    "def validate(model, val_dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            decoded_preds = [\n",
    "                tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "                for g in generated_ids\n",
    "            ]\n",
    "            decoded_labels = [\n",
    "                tokenizer.decode(l, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "                for l in labels\n",
    "            ]\n",
    "            \n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_labels)\n",
    "    \n",
    "    results = rouge.compute(predictions=predictions, references=references)\n",
    "    model.train()\n",
    "    return results, predictions\n",
    "\n",
    "# -------------------------\n",
    "# 11. 학습 루프\n",
    "# -------------------------\n",
    "best_rouge_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "scaler = GradScaler()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss.mean()  # 단일 GPU라면 보통 scalar지만, .mean() 유지 가능\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"\\n=== Epoch {epoch+1} Done ===\")\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # 검증\n",
    "    val_results, val_predictions = validate(model, val_dataloader, tokenizer, device)\n",
    "    print(f\"Validation ROUGE: {val_results}\")\n",
    "\n",
    "    rouge_l_score = val_results[\"rougeL\"]\n",
    "    if rouge_l_score > best_rouge_score:\n",
    "        best_rouge_score = rouge_l_score\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "        # 모델 체크포인트 저장\n",
    "        model.save_pretrained(\"./summary_model_checkpoint\")\n",
    "        tokenizer.save_pretrained(\"./summary_model_checkpoint\")\n",
    "        print(f\"** Best model saved at epoch {best_epoch} with ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 12. 최종 모델 저장\n",
    "# -------------------------\n",
    "model.save_pretrained(\"./summary_model_final\")\n",
    "tokenizer.save_pretrained(\"./summary_model_final\")\n",
    "\n",
    "print(\"학습 및 검증 완료!\")\n",
    "print(f\"Best epoch: {best_epoch}, Best ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "# GPU 캐시 정리\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8f87e89a9241b98674bdb107b1df9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading JSON from pre_data/Training/TL1:   0%|          | 0/84364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f080340380349f78fbc339097767ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading JSON from pre_data/Validation/VL1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 84364\n",
      "Validation 데이터 개수: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865b326e0afd49ef9f1ebbbffcff3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/21091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1 Done ===\n",
      "Average Train Loss: 1.9132\n",
      "Validation ROUGE: {'rouge1': 0.06877769452769443, 'rouge2': 0.015111782106782112, 'rougeL': 0.06825757381507366, 'rougeLsum': 0.06832091186591174}\n",
      "** Best model saved at epoch 1 with ROUGE-L: 0.0683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df5344099248259ca0a09dad352f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/21091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 2 Done ===\n",
      "Average Train Loss: 1.3922\n",
      "Validation ROUGE: {'rouge1': 0.07248212454212435, 'rouge2': 0.015642640692640694, 'rougeL': 0.07195047924297901, 'rougeLsum': 0.071904023199023}\n",
      "** Best model saved at epoch 2 with ROUGE-L: 0.0720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59ccadbf2044a80b2fe50684d223acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/21091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 3 Done ===\n",
      "Average Train Loss: 1.0955\n",
      "Validation ROUGE: {'rouge1': 0.07328302836052812, 'rouge2': 0.016068253968253968, 'rougeL': 0.07264224636474612, 'rougeLsum': 0.07289302253302227}\n",
      "** Best model saved at epoch 3 with ROUGE-L: 0.0726\n",
      "학습 및 검증 완료!\n",
      "Best epoch: 3, Best ROUGE-L: 0.0726\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    BartForConditionalGeneration, \n",
    "    PreTrainedTokenizerFast,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import evaluate\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# -------------------------\n",
    "# 1. 데이터 로드 함수\n",
    "# -------------------------\n",
    "def load_preprocessed_data(base_dir):\n",
    "    input_texts = []\n",
    "    target_summaries = []\n",
    "    all_files = []\n",
    "    \n",
    "    # 먼저 모든 파일 경로를 수집\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # tqdm으로 진행률 표시\n",
    "    for file_path in tqdm(all_files, desc=f\"Loading JSON from {base_dir}\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            passage = \" \".join([f\"{d['character']}: {d['dialogue']}\" for d in data[\"passage\"]])\n",
    "            summary = data[\"summaries\"].get(\"Summary1\", \"\")\n",
    "            \n",
    "            if passage and summary:\n",
    "                input_texts.append(passage)\n",
    "                target_summaries.append(summary)\n",
    "    \n",
    "    return input_texts, target_summaries\n",
    "\n",
    "# -------------------------\n",
    "# 2. 데이터 로드\n",
    "# -------------------------\n",
    "train_base_dir = \"pre_data/Training/TL1\"\n",
    "val_base_dir = \"pre_data/Validation/VL1\"\n",
    "\n",
    "train_input_texts, train_target_summaries = load_preprocessed_data(train_base_dir)\n",
    "val_input_texts, val_target_summaries = load_preprocessed_data(val_base_dir)\n",
    "\n",
    "print(f\"Train 데이터 개수: {len(train_input_texts)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_input_texts)}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. 모델 및 토크나이저 로드 (KoBART)\n",
    "# -------------------------\n",
    "model_name = \"gogamza/kobart-base-v1\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, config=model_config)\n",
    "\n",
    "# -------------------------\n",
    "# 4. GPU 사용 설정 (단일 GPU로만 사용)\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -------------------------\n",
    "# 5. 토큰화 함수 (chunk 단위로 처리 + 진행 표시)\n",
    "# -------------------------\n",
    "def preprocess_for_model(\n",
    "    input_texts, \n",
    "    target_summaries, \n",
    "    tokenizer, \n",
    "    max_input_length=1024, \n",
    "    max_target_length=128\n",
    "):\n",
    "    inputs = tokenizer(\n",
    "        input_texts,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        target_summaries,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return inputs, targets\n",
    "\n",
    "# -------------------------\n",
    "# 6. 실제 토큰화 실행\n",
    "# -------------------------\n",
    "train_inputs, train_targets = preprocess_for_model(train_input_texts, train_target_summaries, tokenizer)\n",
    "val_inputs, val_targets = preprocess_for_model(val_input_texts, val_target_summaries, tokenizer)\n",
    "\n",
    "# -------------------------\n",
    "# 7. Dataset 클래스 정의\n",
    "# -------------------------\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
    "            \"labels\": self.targets[\"input_ids\"][idx],\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# 8. Dataset 생성\n",
    "# -------------------------\n",
    "train_dataset = SummaryDataset(train_inputs, train_targets)\n",
    "val_dataset = SummaryDataset(val_inputs, val_targets)\n",
    "\n",
    "# -------------------------\n",
    "# 9. DataLoader 생성 (num_workers 활용)\n",
    "# -------------------------\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=0  # 멀티프로세스 로딩\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 10. 옵티마이저 및 스케줄러\n",
    "# -------------------------\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 11. 평가용 메트릭 (ROUGE)\n",
    "# -------------------------\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# -------------------------\n",
    "# 12. 검증(Validation) 함수\n",
    "# -------------------------\n",
    "def validate(model, val_dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # 단일 GPU -> model.generate 사용\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            decoded_preds = [\n",
    "                tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "                for g in generated_ids\n",
    "            ]\n",
    "            decoded_labels = [\n",
    "                tokenizer.decode(l, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "                for l in labels\n",
    "            ]\n",
    "            \n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_labels)\n",
    "    \n",
    "    results = rouge.compute(predictions=predictions, references=references)\n",
    "    model.train()\n",
    "    return results, predictions\n",
    "\n",
    "# -------------------------\n",
    "# 13. 학습 루프\n",
    "# -------------------------\n",
    "best_rouge_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "scaler = GradScaler()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            # 만약 여러 GPU를 사용했을 때 shape가 달라지는 걸 대비해 .mean() 유지 가능\n",
    "            # 하지만 단일 GPU라면 보통 scalar로 나옵니다.\n",
    "            loss = outputs.loss.mean()\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"\\n=== Epoch {epoch+1} Done ===\")\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- 검증 ---\n",
    "    val_results, val_predictions = validate(model, val_dataloader, tokenizer, device)\n",
    "    print(f\"Validation ROUGE: {val_results}\")\n",
    "\n",
    "    rouge_l_score = val_results[\"rougeL\"]\n",
    "    if rouge_l_score > best_rouge_score:\n",
    "        best_rouge_score = rouge_l_score\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "        # 단일 GPU, DataParallel 제거 -> 그냥 model 저장\n",
    "        model.save_pretrained(\"./summary_model_checkpoint\")\n",
    "        tokenizer.save_pretrained(\"./summary_model_checkpoint\")\n",
    "        print(f\"** Best model saved at epoch {best_epoch} with ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 14. 최종 모델 저장\n",
    "# -------------------------\n",
    "model.save_pretrained(\"./summary_model_final\")\n",
    "tokenizer.save_pretrained(\"./summary_model_final\")\n",
    "\n",
    "print(\"학습 및 검증 완료!\")\n",
    "print(f\"Best epoch: {best_epoch}, Best ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 84364\n",
      "Validation 데이터 개수: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "c:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d679f819404421917a4f0f39e396b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/14061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 174\u001b[0m\n\u001b[0;32m    167\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m    168\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    169\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    170\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m--> 174\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    176\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zqrc0\\anaconda3\\envs\\summary\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# KoBART 관련\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
    "import evaluate\n",
    "\n",
    "# 추가\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "# 1. 데이터 로드 함수\n",
    "def load_preprocessed_data(base_dir):\n",
    "    input_texts = []\n",
    "    target_summaries = []\n",
    "    \n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    passage = \" \".join([f\"{d['character']}: {d['dialogue']}\" for d in data[\"passage\"]])\n",
    "                    summary = data[\"summaries\"].get(\"Summary1\", \"\")\n",
    "                    \n",
    "                    if passage and summary:\n",
    "                        input_texts.append(passage)\n",
    "                        target_summaries.append(summary)\n",
    "    return input_texts, target_summaries\n",
    "\n",
    "# 2. 데이터 로드\n",
    "train_base_dir = \"./pre_data/Training/TL1\"\n",
    "val_base_dir = \"./pre_data/Validation/VL1\"\n",
    "\n",
    "train_input_texts, train_target_summaries = load_preprocessed_data(train_base_dir)\n",
    "val_input_texts, val_target_summaries = load_preprocessed_data(val_base_dir)\n",
    "\n",
    "# Train 데이터와 Validation 데이터의 개수 출력\n",
    "print(f\"Train 데이터 개수: {len(train_input_texts)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_input_texts)}\")\n",
    "\n",
    "# 4. 모델 및 토크나이저 로드 (KoBART)\n",
    "model_name = \"gogamza/kobart-base-v1\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 5. GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 6. 데이터 전처리 함수\n",
    "def preprocess_for_model(input_texts, target_summaries, tokenizer, max_input_length=1024, max_target_length=128):\n",
    "    inputs = tokenizer(\n",
    "        input_texts,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        target_summaries,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return inputs, targets\n",
    "\n",
    "# 7. 토큰화 (Train, Validation 각각)\n",
    "train_inputs, train_targets = preprocess_for_model(train_input_texts, train_target_summaries, tokenizer)\n",
    "val_inputs, val_targets = preprocess_for_model(val_input_texts, val_target_summaries, tokenizer)\n",
    "\n",
    "# 8. Dataset 클래스 정의\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
    "            \"labels\": self.targets[\"input_ids\"][idx],\n",
    "        }\n",
    "\n",
    "# 9. Dataset 생성\n",
    "train_dataset = SummaryDataset(train_inputs, train_targets)\n",
    "val_dataset = SummaryDataset(val_inputs, val_targets)\n",
    "\n",
    "# 10. DataLoader 생성\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 11. 옵티마이저 및 스케줄러 설정\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# 12. 평가용 메트릭 (ROUGE)\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# 13. 검증(Validation) 함수\n",
    "def validate(model, val_dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            decoded_preds = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_ids]\n",
    "            decoded_labels = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
    "            \n",
    "            predictions.extend(decoded_preds)\n",
    "            references.extend(decoded_labels)\n",
    "    \n",
    "    results = rouge.compute(predictions=predictions, references=references)\n",
    "    model.train()\n",
    "    return results, predictions\n",
    "\n",
    "# ----------------------------\n",
    "# 14. 학습 루프 (Train + Validation)\n",
    "# ----------------------------\n",
    "best_rouge_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "scaler = GradScaler()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # tqdm을 이용한 진행률 표시\n",
    "    # desc: 진행 표시줄 왼쪽에 표시될 문구\n",
    "    # total: (선택) 총 step 개수를 명시적으로 표시하고 싶다면 len(train_dataloader)를 전달 가능\n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"\\n=== Epoch {epoch+1} Done ===\")\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- 검증(Validation) ---\n",
    "    val_results, val_predictions = validate(model, val_dataloader, tokenizer, device)\n",
    "    print(f\"Validation ROUGE: {val_results}\")\n",
    "\n",
    "    rouge_l_score = val_results[\"rougeL\"]\n",
    "    if rouge_l_score > best_rouge_score:\n",
    "        best_rouge_score = rouge_l_score\n",
    "        best_epoch = epoch + 1\n",
    "        model.save_pretrained(f\"./summary_model_checkpoint\")\n",
    "        tokenizer.save_pretrained(f\"./summary_model_checkpoint\")\n",
    "        print(f\"** Best model saved at epoch {best_epoch} with ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "# 15. 최종 모델 저장\n",
    "model.save_pretrained(\"./summary_model_final\")\n",
    "tokenizer.save_pretrained(\"./summary_model_final\")\n",
    "\n",
    "print(\"학습 및 검증 완료!\")\n",
    "print(f\"Best epoch: {best_epoch}, Best ROUGE-L: {best_rouge_score:.4f}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

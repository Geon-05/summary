{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 불필요한 공백 및 특수 문자를 제거합니다.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # 다중 공백을 하나로 변환\n",
    "    text = text.strip()  # 양 끝 공백 제거\n",
    "    return text\n",
    "\n",
    "def extract_characters_and_lines(passage):\n",
    "    \"\"\"\n",
    "    등장인물과 대화를 추출합니다.\n",
    "    \"\"\"\n",
    "    lines = passage.split(\"\\n\")\n",
    "    dialogues = []\n",
    "    for line in lines:\n",
    "        match = re.match(r\"(.*?)\\](.*)\", line)  # 예: 기준모] 대사\n",
    "        if match:\n",
    "            character, dialogue = match.groups()\n",
    "            dialogues.append({\"character\": character.strip(), \"dialogue\": clean_text(dialogue)})\n",
    "    return dialogues\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    JSON 데이터셋을 전처리하여 필요한 정보만 추출합니다.\n",
    "    \"\"\"\n",
    "    meta = data.get(\"Meta\", {})\n",
    "    annotation = data.get(\"Annotation\", {})\n",
    "\n",
    "    # 주요 정보 추출\n",
    "    passage = meta.get(\"passage\", \"\")\n",
    "    summaries = {key: clean_text(value) for key, value in annotation.items() if value}\n",
    "\n",
    "    # 등장인물 및 대사 추출\n",
    "    dialogues = extract_characters_and_lines(passage)\n",
    "\n",
    "    # 전처리된 결과 반환\n",
    "    return {\n",
    "        \"doc_id\": meta.get(\"doc_id\"),\n",
    "        \"passage\": dialogues,\n",
    "        \"summaries\": summaries\n",
    "    }\n",
    "\n",
    "def create_preprocessed_dir_structure(base_dir):\n",
    "    \"\"\"\n",
    "    기존 디렉토리 구조를 바탕으로 'pre_' 접두사를 붙인 새로운 디렉토리 구조 생성\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for dir_name in dirs:\n",
    "            new_dir = os.path.join(root, f\"pre_{dir_name}\")\n",
    "            if not os.path.exists(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "\n",
    "def process_all_json_files(base_dir):\n",
    "    \"\"\"\n",
    "    모든 JSON 파일을 순회하며 전처리하고 새로운 폴더에 저장\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if not any(d.startswith(\"pre_\") for d in dirs):\n",
    "            # 새로운 디렉토리 생성\n",
    "            create_preprocessed_dir_structure(root)\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # 파일 읽기\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # 데이터 전처리\n",
    "                processed_data = preprocess_data(data)\n",
    "\n",
    "                # 저장 경로 생성\n",
    "                relative_path = os.path.relpath(root, base_dir)\n",
    "                preprocessed_dir = os.path.join(base_dir, f\"pre_{relative_path}\")\n",
    "                preprocessed_file_path = os.path.join(preprocessed_dir, file)\n",
    "\n",
    "                # 파일 저장\n",
    "                os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "                with open(preprocessed_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 실행 코드\n",
    "base_directory = \"./\"  # 루트 디렉토리 경로 설정\n",
    "process_all_json_files(base_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"doc_id\": \"SCRIPT-culture-00001\",\n",
      "    \"passage\": [],\n",
      "    \"summaries\": {\n",
      "        \"Summary1\": \"경기가 끝나고 해변가에서 열린 파티에 참석했고, 다음날 시장의 초대로 작은 마을에 가서 아사도를 먹었다.\",\n",
      "        \"Summary2\": \"경기가 끝나고 폴로 선수와 마을 사람들까지 모여 해변에서는 파티가 열렸다. 200인분의 파에야가 완성되고, 촬영하는 취재진까지 챙겨주신 '아저씨' 덕에 발데스 반도에서의 하루가 파티로 마무리되었다. 다음날 시장의 초대로 베인 티오 초 데 홀리오라는 작은 마을에 가서 그곳 사람들이 평소 주말에 먹는다는 아사도를 먹었다.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 불필요한 공백 및 특수 문자를 제거합니다.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\\\s+\", \" \", text)  # 다중 공백을 하나로 변환\n",
    "    text = text.strip()  # 양 끝 공백 제거\n",
    "    return text\n",
    "\n",
    "def extract_characters_and_lines(passage):\n",
    "    \"\"\"\n",
    "    등장인물과 대화를 추출합니다.\n",
    "    \"\"\"\n",
    "    lines = passage.split(\"\\\\n\")\n",
    "    dialogues = []\n",
    "    for line in lines:\n",
    "        match = re.match(r\"(.*?)\\\\](.*)\", line)  # 예: 기준모] 대사\n",
    "        if match:\n",
    "            character, dialogue = match.groups()\n",
    "            dialogues.append({\"character\": character.strip(), \"dialogue\": clean_text(dialogue)})\n",
    "    return dialogues\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    JSON 데이터셋을 전처리하여 필요한 정보만 추출합니다.\n",
    "    \"\"\"\n",
    "    meta = data.get(\"Meta\", {})\n",
    "    annotation = data.get(\"Annotation\", {})\n",
    "\n",
    "    # 주요 정보 추출\n",
    "    passage = meta.get(\"passage\", \"\")\n",
    "    summaries = {key: clean_text(value) for key, value in annotation.items() if value}\n",
    "\n",
    "    # 등장인물 및 대사 추출\n",
    "    dialogues = extract_characters_and_lines(passage)\n",
    "\n",
    "    # 전처리된 결과 반환\n",
    "    return {\n",
    "        \"doc_id\": meta.get(\"doc_id\"),\n",
    "        \"passage\": dialogues,\n",
    "        \"summaries\": summaries\n",
    "    }\n",
    "\n",
    "# JSON 파일 로드\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# 데이터 파일 경로\n",
    "file_path = \"culture/3sent/SCRIPT-culture-00001-00006.json\"\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "raw_data = load_json_file(file_path)\n",
    "processed_data = preprocess_data(raw_data)\n",
    "\n",
    "# 전처리된 데이터 저장 (옵션)\n",
    "output_file = \"processed_data.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(processed_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 결과 출력\n",
    "print(json.dumps(processed_data, ensure_ascii=False, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
